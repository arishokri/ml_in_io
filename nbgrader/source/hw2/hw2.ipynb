{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "87809626",
      "metadata": {},
      "source": [
        "# Homework: Employee Analytics (NumPy + pandas + Matplotlib)\n",
        "\n",
        "**Total: 100 points** • **Questions: 15**\n",
        "\n",
        "This homework uses one dataset: **employee_data** (CSV). You will practice:\n",
        "\n",
        "- NumPy arrays + vectorized operations\n",
        "- pandas Series/DataFrame operations (filtering, cleaning, `groupby`, aggregates, pivots)\n",
        "- Matplotlib plotting (pyplot + OO-style where appropriate)\n",
        "\n",
        "**Dataset columns (expected):**\n",
        "\n",
        "`Employee_ID, Age, Salary, Gender, Department, Experience, Education, Performance_Score, Working_Hours, City, Country, Years_in_Company, Previous_Company, Annual_Bonus, Join_Date, Name`\n",
        "\n",
        "> You may assume `Employee_ID` is unique.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "418548d9",
      "metadata": {},
      "source": [
        "## Instructions (important)\n",
        "\n",
        "- Use **pandas** for table operations, and **NumPy** for vectorized computations where asked.\n",
        "- Do **not** hard-code answers; compute them from the data.\n",
        "- Unless specified, treat missing values carefully (e.g., `NaN` in Hire Date/Bonus).\n",
        "- Most questions ask you to create specific variables. **Name them exactly** as requested.\n",
        "- Plots must have: title, axis labels, and readable tick labels.\n",
        "- If you're using Google Colab, you need to upload the downloaded dataset to your Colab Files section.\n",
        "\n",
        "### Grading\n",
        "\n",
        "This notebook uses autograding:\n",
        "\n",
        "- **Answer cells** are marked as `# YOUR CODE HERE` and will be graded.\n",
        "- Remove `raise NotImplementedError()` once you start working on a solution.\n",
        "- Only write your code where instructed. DO NOT ADD or REMOVE any cells. This may break the notebook.\n",
        "- Do not edit the content of LOCKED cells.\n",
        "- Besides the sanity check tests visible to you, we might use additional rigorous hidden tests that are only available after submission. Double-check your work for accuracy and do not rely on sanity checks.\n",
        "- This notebook contains metadata and tracking.\n",
        "- If anything breaks, save your work and download a fresh copy of the notebook from Canvas. You can copy your finished code and insert individually into appropriate cells of the new copy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64d18e20",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "setup",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# Setup\n",
        "import hashlib\n",
        "import warnings\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "SALT = b\"ml_io_hw2\"\n",
        "\n",
        "\n",
        "def dataframe_digest(df: pd.DataFrame) -> str:\n",
        "    \"\"\"\n",
        "    Returns hexdigest of the hashed value of a given pands dataframe.\n",
        "    \"\"\"\n",
        "    row_hashes = pd.util.hash_pandas_object(df, index=True)\n",
        "    h = hashlib.sha256()\n",
        "    h.update(row_hashes.values.tobytes())\n",
        "    return h.hexdigest()\n",
        "\n",
        "\n",
        "def hash_float(x, *, decimals=6, salt=SALT) -> str:\n",
        "    \"\"\"\n",
        "    Hash a scalar float in a stable, tolerance-aware way.\n",
        "    \"\"\"\n",
        "    x = float(np.round(x, decimals))\n",
        "    h = hashlib.sha256()\n",
        "    h.update(salt)\n",
        "    h.update(np.float64(x).tobytes())\n",
        "    return h.hexdigest()\n",
        "\n",
        "\n",
        "def hash_value_counts(vc: pd.Series, *, salt=SALT) -> str:\n",
        "    \"\"\"\n",
        "    Stable hash for value_counts() output.\n",
        "    Order-insensitive and index-aware.\n",
        "    \"\"\"\n",
        "    vc = vc.sort_index()\n",
        "    row_hashes = pd.util.hash_pandas_object(vc, index=True).to_numpy(dtype=np.uint64)\n",
        "    h = hashlib.sha256()\n",
        "    h.update(salt)\n",
        "    h.update(row_hashes.tobytes())\n",
        "    return h.hexdigest()\n",
        "\n",
        "\n",
        "pd.set_option(\"display.max_columns\", 50)\n",
        "pd.set_option(\"display.width\", 140)\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fd280c3",
      "metadata": {},
      "source": [
        "## Load the dataset\n",
        "\n",
        "Place your CSV in the same folder as this notebook and name it **`employee_data.csv`**.\n",
        "\n",
        "If your file has a different name, change `DATA_PATH` accordingly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e6ae633",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "load_data",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "outputs": [],
      "source": [
        "DATA_PATH = \"employee_data.csv\"\n",
        "\n",
        "# Load\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "\n",
        "\n",
        "# Basic cleanup: strip whitespace in column names and some string fields\n",
        "df.columns = df.columns.str.strip()\n",
        "for col in [\n",
        "    \"City\",\n",
        "    \"Country\",\n",
        "    \"Department\",\n",
        "    \"Gender\",\n",
        "    \"Education\",\n",
        "    \"Name\",\n",
        "    \"Previous_Company\",\n",
        "]:\n",
        "    if col in df.columns:\n",
        "        df[col] = df[col].astype(\"string\").str.strip()\n",
        "\n",
        "# Parse dates\n",
        "if \"Join_Date\" in df.columns:\n",
        "    df[\"Join_Date\"] = pd.to_datetime(df[\"Join_Date\"], errors=\"coerce\")\n",
        "\n",
        "assert (\n",
        "    dataframe_digest(df)\n",
        "    == \"aeb852f872aa59e9be8e8afa192617ced6070fe7a45a30c02b6f7f158457a9bd\"\n",
        "), (\n",
        "    \"Your dataframe was not loaded correctly. Ensure your .csv file is not corrupted and try again.\"\n",
        ")\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f102ca0",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Part A — Data understanding & cleaning (30 points)\n",
        "\n",
        "### Q1 (4 pts) — Basic structure\n",
        "\n",
        "Create the following variables:\n",
        "\n",
        "- `n_rows`: number of rows\n",
        "- `n_cols`: number of columns\n",
        "- `colnames`: list of column names in order\n",
        "\n",
        "**Hint:** `df.shape`, `df.columns`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36c18732",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "q1_basic_structure",
          "locked": false,
          "schema_version": 3,
          "solution": true
        }
      },
      "outputs": [],
      "source": [
        "# n_rows = ...\n",
        "# n_cols = ...\n",
        "# colnames = ...\n",
        "\n",
        "# Be sure to remove raise NotImplementedError()\n",
        "### BEGIN SOLUTION\n",
        "n_rows, n_cols = df.shape\n",
        "colnames = df.columns.tolist()\n",
        "### END SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eff8a6e3",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "q1_basic_structure_tests",
          "locked": true,
          "points": 4,
          "schema_version": 3,
          "solution": false
        }
      },
      "outputs": [],
      "source": [
        "assert isinstance(n_rows, int) and n_rows > 0\n",
        "assert isinstance(n_cols, int) and n_cols > 0\n",
        "assert isinstance(colnames, list) and len(colnames) == n_cols\n",
        "\n",
        "### BEGIN HIDDEN TESTS\n",
        "assert n_rows == 100000\n",
        "assert n_cols == 16\n",
        "assert colnames == [\n",
        "    \"Employee_ID\",\n",
        "    \"Age\",\n",
        "    \"Salary\",\n",
        "    \"Gender\",\n",
        "    \"Department\",\n",
        "    \"Experience\",\n",
        "    \"Education\",\n",
        "    \"Performance_Score\",\n",
        "    \"Working_Hours\",\n",
        "    \"City\",\n",
        "    \"Country\",\n",
        "    \"Years_in_Company\",\n",
        "    \"Previous_Company\",\n",
        "    \"Annual_Bonus\",\n",
        "    \"Join_Date\",\n",
        "    \"Name\",\n",
        "]\n",
        "### END HIDDEN TESTS"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2f2b8ef",
      "metadata": {},
      "source": [
        "### Q2 (6 pts) — Clean numeric columns\n",
        "\n",
        "Ensure these columns are numeric (float or int), coercing errors to missing:\n",
        "\n",
        "- `Salary`\n",
        "- `Annual_Bonus`\n",
        "- `Working_Hours`\n",
        "- `Performance_Score`\n",
        "- `Age`\n",
        "\n",
        "Store the cleaned DataFrame as `df_clean` (do not overwrite `df`).\n",
        "\n",
        "**Hint:** `pd.to_numeric(..., errors=\"coerce\")`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fe6885c",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "q2_clean_numeric",
          "locked": false,
          "schema_version": 3,
          "solution": true
        }
      },
      "outputs": [],
      "source": [
        "df_clean = ...\n",
        "\n",
        "### BEGIN SOLUTION\n",
        "df_clean = df.copy()\n",
        "for c in [\"Salary\", \"Annual_Bonus\", \"Working_Hours\", \"Performance_Score\", \"Age\"]:\n",
        "    df_clean[c] = pd.to_numeric(df_clean[c], errors=\"coerce\")\n",
        "### END SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f059b137",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "q2_clean_numeric_test_1",
          "locked": true,
          "points": 5,
          "schema_version": 3,
          "solution": false
        }
      },
      "outputs": [],
      "source": [
        "assert isinstance(df_clean, pd.DataFrame), \"df_clean must be a pandas DataFrame\"\n",
        "\n",
        "### BEGIN HIDDEN TESTS\n",
        "required = [\"Salary\", \"Annual_Bonus\", \"Working_Hours\", \"Performance_Score\", \"Age\"]\n",
        "for c in required:\n",
        "    assert c in df_clean.columns\n",
        "    assert pd.api.types.is_numeric_dtype(df_clean[c]), f\"{c} must be numeric\"\n",
        "### END HIDDEN TESTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4e0198f",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "q2_clean_numeric_test_2",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false
        }
      },
      "outputs": [],
      "source": [
        "assert (\n",
        "    dataframe_digest(df)\n",
        "    == \"aeb852f872aa59e9be8e8afa192617ced6070fe7a45a30c02b6f7f158457a9bd\"\n",
        "), (\n",
        "    \"The original dataframe is manpulated. Make sure you create new deep copies of dataframe and do not write back on it.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67d4f51c",
      "metadata": {},
      "source": [
        "### Q3 (6 pts) — Missingness report\n",
        "\n",
        "Create a DataFrame `missing_report` with columns:\n",
        "\n",
        "- `missing_count`\n",
        "- `missing_pct`\n",
        "\n",
        "for every column in `df_clean`, sorted by `missing_pct` descending.\n",
        "\n",
        "**Hint:** `isna().sum()`, divide by `len(df_clean)`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45c2668d",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "q3_missing_report",
          "locked": false,
          "schema_version": 3,
          "solution": true
        }
      },
      "outputs": [],
      "source": [
        "# You can first calculate and store the values of the columns in separate objects as intermediary step.\n",
        "# missing_count = ...\n",
        "# missing_pct = ...\n",
        "# missing_report = ...\n",
        "\n",
        "### BEGIN SOLUTION\n",
        "missing_count = df_clean.isna().sum()\n",
        "missing_pct = missing_count / len(df_clean) * 100\n",
        "missing_report = pd.DataFrame(\n",
        "    {\"missing_count\": missing_count, \"missing_pct\": missing_pct}\n",
        ").sort_values(\"missing_pct\", ascending=False)\n",
        "### END SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20b1d2f4",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "q3_missing_report_tests",
          "locked": true,
          "points": 6,
          "schema_version": 3,
          "solution": false
        }
      },
      "outputs": [],
      "source": [
        "assert isinstance(missing_report, pd.DataFrame)\n",
        "assert (\n",
        "    \"missing_count\" in missing_report.columns\n",
        "    and \"missing_pct\" in missing_report.columns\n",
        ")\n",
        "assert missing_report.index.is_unique, (\n",
        "    \"the row index values of missing_report should be unique\"\n",
        ")\n",
        "\n",
        "assert (\n",
        "    hash_float(missing_report.sum()[\"missing_count\"])\n",
        "    == \"ef9433bbeb1b4ee2103c0d6027351186102cb9ed8c18845575814fc3c9c454dc\"\n",
        "), \"missing_count is not accurate.\"\n",
        "assert (\n",
        "    hash_float(missing_report.sum()[\"missing_pct\"])\n",
        "    == \"4948daac02cee6d9928777e1a14764fc745fe1cc7ff431601132b8cd08564961\"\n",
        "), \"missing_pct is not accurate\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14078f73",
      "metadata": {},
      "source": [
        "### Q4 (7 pts) — Create derived features\n",
        "\n",
        "Add the following columns to `df_clean`:\n",
        "\n",
        "1. `Total_Comp` = `Salary` + `Annual_Bonus` (treat missing bonus as 0; missing salary should remain NaN)\n",
        "2. `Overtime` = `Working_Hours` - 40 (but minimum 0; if Working_Hours is missing, Overtime should be NaN)\n",
        "3. `Tenure_Bucket` based on `Years_in_Company`:\n",
        "   - `\"0-2\"`, `\"3-5\"`, `\"6-10\"`, `\"11+\"`\n",
        "\n",
        "Return the updated DataFrame as `df_feat`.\n",
        "\n",
        "**Hints:**\n",
        "\n",
        "- Bonus fill: `df[\"Annual_Bonus\"].fillna(0)`\n",
        "- For minimum 0: `np.maximum(...)`\n",
        "- Buckets: `pd.cut(...)` or `np.select(...)`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c164639b",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "q4_derived_features",
          "locked": false,
          "schema_version": 3,
          "solution": true
        }
      },
      "outputs": [],
      "source": [
        "df_feat = df_clean.copy()\n",
        "\n",
        "### BEGIN SOLUTION\n",
        "# Total comp: treat missing bonus as 0, but keep Salary NaN if missing\n",
        "df_feat[\"Total_Comp\"] = df_feat[\"Salary\"] + df_feat[\"Annual_Bonus\"].fillna(0)\n",
        "\n",
        "# Overtime: min 0; preserve NaN if Working_Hours is NaN\n",
        "ot = df_feat[\"Working_Hours\"] - 40\n",
        "df_feat[\"Overtime\"] = np.where(\n",
        "    df_feat[\"Working_Hours\"].isna(), np.nan, np.maximum(ot, 0)\n",
        ")\n",
        "\n",
        "# Tenure buckets (assumes Years_in_Company is numeric-ish; coerce to numeric defensively)\n",
        "ten = pd.to_numeric(df_feat[\"Years_in_Company\"], errors=\"coerce\")\n",
        "bins = [-np.inf, 2, 5, 10, np.inf]\n",
        "labels = [\"0-2\", \"3-5\", \"6-10\", \"11+\"]\n",
        "df_feat[\"Tenure_Bucket\"] = pd.cut(ten, bins=bins, labels=labels)\n",
        "### END SOLUTION\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "440861ff",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "q4_derived_features_test_1",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "assert isinstance(df_feat, pd.DataFrame)\n",
        "assert all(c in df_feat.columns for c in [\"Total_Comp\", \"Overtime\", \"Tenure_Bucket\"]), (\n",
        "    \"All requested columns must be present in df_feat\"\n",
        ")\n",
        "### BEGIN HIDDEN TESTS\n",
        "assert str(df_feat[\"Tenure_Bucket\"].dtype) == \"category\", (\n",
        "    \"Tenure_Bucket should be a categorical type\"\n",
        ")\n",
        "### END HIDDEN TESTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e8f7ad5",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "q4_derived_features_test_2",
          "locked": true,
          "points": 3,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "assert (\n",
        "    hash_float(df_feat[\"Total_Comp\"].sum())\n",
        "    == \"66d803c4b4973e37762a2b1e4cd054aaec6b36288e18f1cbb83776b4604b5743\"\n",
        "), \"Total_Comp values are not accurate.\"\n",
        "\n",
        "assert (\n",
        "    hash_float(df_feat[\"Overtime\"].sum())\n",
        "    == \"ed09a59c80f1d2100797e9044eddda9697d021b70eb0fd51329f35179663e4e4\"\n",
        "), \"Overtime values are not accurate.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79a02d2a",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "q4_derived_features_test_3",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "vc = (\n",
        "    df_feat[\"Tenure_Bucket\"]\n",
        "    .value_counts()\n",
        "    .reindex([\"0-2\", \"3-5\", \"6-10\", \"11+\"], fill_value=0)\n",
        ")\n",
        "assert (\n",
        "    hash_value_counts(vc)\n",
        "    == \"c01867a9d50354bd6f66490c6f255825b3c056b7a4cde43d128e390710ea0f9f\"\n",
        "), \"Tenure_Bucket distribution is not accurate.\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "914c4652",
      "metadata": {},
      "source": [
        "### Q5 (7 pts) — Fix whitespace & categories\n",
        "\n",
        "Create a DataFrame `df_cat` where:\n",
        "\n",
        "- `Gender`, `Department`, `Country` are converted to pandas `category` dtype\n",
        "- `City` is stripped of whitespace\n",
        "\n",
        "Return `df_cat`.\n",
        "\n",
        "**Hint:** `astype(\"category\")`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1984f6a6",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "q5_categories",
          "locked": false,
          "schema_version": 3,
          "solution": true
        }
      },
      "outputs": [],
      "source": [
        "df_cat = df_feat.copy()\n",
        "\n",
        "### BEGIN SOLUTION\n",
        "for c in [\"Gender\", \"Department\", \"Country\"]:\n",
        "    df_cat[c] = df_cat[c].astype(\"category\")\n",
        "df_cat[\"City\"] = df_cat[\"City\"].astype(\"string\").str.strip()\n",
        "### END SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c15a5d6d",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "q5_categories_tests",
          "locked": true,
          "points": 7,
          "schema_version": 3,
          "solution": false
        }
      },
      "outputs": [],
      "source": [
        "for c in [\"Gender\", \"Department\", \"Country\"]:\n",
        "    assert c in df_cat.columns\n",
        "    assert str(df_cat[c].dtype) == \"category\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9693c4a",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Part B — Analysis with aggregations & groupby (45 points)\n",
        "\n",
        "### Q6 (6 pts) — Department salary summary\n",
        "\n",
        "Create `dept_salary_summary` as a DataFrame indexed by `Department` with columns:\n",
        "\n",
        "- `count` (non-missing salaries)\n",
        "- `mean_salary`\n",
        "- `median_salary`\n",
        "\n",
        "Sorted by `mean_salary` descending.\n",
        "\n",
        "**Hint:** `groupby(\"Department\")[\"Salary\"].agg(...)`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4148df60",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "q6_dept_salary_summary",
          "locked": false,
          "schema_version": 3,
          "solution": true
        }
      },
      "outputs": [],
      "source": [
        "# dept_salary_summary = ...\n",
        "### BEGIN SOLUTION\n",
        "dept_salary_summary = (\n",
        "    df_cat.groupby(\"Department\")[\"Salary\"]\n",
        "    .agg(count=\"count\", mean_salary=\"mean\", median_salary=\"median\")\n",
        "    .sort_values(\"mean_salary\", ascending=False)\n",
        ")\n",
        "### END SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c374d85",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "q6_dept_salary_summary_test_1",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "assert isinstance(dept_salary_summary, pd.DataFrame)\n",
        "for c in [\"count\", \"mean_salary\", \"median_salary\"]:\n",
        "    assert c in dept_salary_summary.columns, (\n",
        "        f\"column {c} not found in dept_salary_summary dataframe\"\n",
        "    )\n",
        "\n",
        "### BEGIN HIDDEN TESTS\n",
        "assert dept_salary_summary.shape == (5, 3), \"The shape of the table is incorrect.\"\n",
        "assert dept_salary_summary.index.to_list() == [\n",
        "    \"Marketing\",\n",
        "    \"Finance\",\n",
        "    \"HR\",\n",
        "    \"Sales\",\n",
        "    \"IT\",\n",
        "], \"The indeces of the summary table are incorrect.\"\n",
        "### END HIDDEN TESTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2554a882",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "q6_dept_salary_summary_test_2",
          "locked": true,
          "points": 4,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "assert (\n",
        "    hash_float(dept_salary_summary.loc[\"Marketing\"].sum())\n",
        "    == \"2ff80081f15c05cadd08c9cedd95ed74111e173f4e43ddcb5383549b632f360a\"\n",
        ")\n",
        "assert (\n",
        "    hash_float(dept_salary_summary.loc[\"Finance\"].sum())\n",
        "    == \"1b085536b0fe25b3f66022671c0146b13ad2e3114b0b4799ca071647dd37f7ca\"\n",
        ")\n",
        "assert (\n",
        "    hash_float(dept_salary_summary.loc[\"IT\"].sum())\n",
        "    == \"45c0c84028dbd3f7f5d4137bbdb6a4bd7286a92e549795ec6027567473fa8f47\"\n",
        ")\n",
        "\n",
        "assert (\n",
        "    hash_float(dept_salary_summary.sum()[\"count\"])\n",
        "    == \"5e59c5099a5ab591bd34d44c644824a0871b537a57134b9dafb725891a12b25f\"\n",
        ")\n",
        "assert (\n",
        "    hash_float(dept_salary_summary.sum()[\"mean_salary\"])\n",
        "    == \"55346e7db096f48a134943698dedf67d3e0d2fb3a97f13e2693972f05e40f229\"\n",
        ")\n",
        "assert (\n",
        "    hash_float(dept_salary_summary.sum()[\"median_salary\"])\n",
        "    == \"5ed6f2e6b9aa8bb00458bd2604cead292a9578028617c9c4538d26cfa202d1f0\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ed77b7a",
      "metadata": {},
      "source": [
        "### Q7 (7 pts) — Gender pay gap by department\n",
        "\n",
        "Compute a table `pay_gap_dept` with one row per department and columns:\n",
        "\n",
        "- `female_mean_salary`\n",
        "- `male_mean_salary`\n",
        "- `gap_m_minus_f` = male_mean_salary - female_mean_salary\n",
        "\n",
        "Departments missing either gender should still appear (gap can be NaN).\n",
        "\n",
        "**Hint:** `pivot_table(index=\"Department\", columns=\"Gender\", values=\"Salary\", aggfunc=\"mean\")`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c5d939c",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "q7_pay_gap_dept",
          "locked": false,
          "schema_version": 3,
          "solution": true
        }
      },
      "outputs": [],
      "source": [
        "# This template is just a suggestion but there are many ways to achieve this.\n",
        "# pt = df_cat.pivot_table(...) # You can first create a pivot table ...\n",
        "# pay_gap_dept = ...\n",
        "\n",
        "### BEGIN SOLUTION\n",
        "pt = df_cat.pivot_table(\n",
        "    index=\"Department\", columns=\"Gender\", values=\"Salary\", aggfunc=\"mean\"\n",
        ")\n",
        "pay_gap_dept = pd.DataFrame(\n",
        "    {\n",
        "        \"female_mean_salary\": pt.get(\"Female\"),\n",
        "        \"male_mean_salary\": pt.get(\"Male\"),\n",
        "    }\n",
        ")\n",
        "pay_gap_dept[\"gap_m_minus_f\"] = (\n",
        "    pay_gap_dept[\"male_mean_salary\"] - pay_gap_dept[\"female_mean_salary\"]\n",
        ")\n",
        "pay_gap_dept = pay_gap_dept.sort_values(\"gap_m_minus_f\", ascending=False)\n",
        "### END SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c96f77d",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "q7_pay_gap_dept_test_1",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "assert isinstance(pay_gap_dept, pd.DataFrame)\n",
        "for c in [\"female_mean_salary\", \"male_mean_salary\", \"gap_m_minus_f\"]:\n",
        "    assert c in pay_gap_dept.columns, f\"column {c} not found in pay_gap_dept dataframe\"\n",
        "\n",
        "### BEGIN HIDDEN TESTS\n",
        "assert pay_gap_dept.shape == (5, 3), \"The number of columns and rows is not as expected\"\n",
        "### END HIDDEN TESTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e21fccb",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "q7_pay_gap_dept_test_2",
          "locked": true,
          "points": 5,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "assert (\n",
        "    hash_float(pay_gap_dept[\"female_mean_salary\"].sum())\n",
        "    == \"f7a01ef2b10dae0100b76b50abfb3bb3ded638522d0d57bfe9b974ffe7fb09a5\"\n",
        "), \"female_mean_salary is not accurate\"\n",
        "assert (\n",
        "    hash_float(pay_gap_dept[\"male_mean_salary\"].sum())\n",
        "    == \"5e4a1900fe96c402205b5a310650ffa5ed2a40f80dda494da4c6c2fe3d1cb124\"\n",
        "), \"male_mean_salary is not accurate\"\n",
        "assert (\n",
        "    hash_float(pay_gap_dept[\"gap_m_minus_f\"].sum())\n",
        "    == \"183790c1c5c7f12e733348905d3512d20074326d7293800bd3dd1a629fcc3d77\"\n",
        "), \"gap_m_minus_f is not accurate\"\n",
        "\n",
        "### BEGIN HIDDEN TESTS\n",
        "row_sa = pay_gap_dept.loc[\"Sales\"]\n",
        "assert np.allclose(\n",
        "    row_sa[[\"female_mean_salary\", \"male_mean_salary\", \"gap_m_minus_f\"]]\n",
        "    .astype(float)\n",
        "    .to_numpy(),\n",
        "    [75065.288, 75200.845, 135.557],\n",
        ")\n",
        "\n",
        "row_ma = pay_gap_dept.loc[\"Marketing\"]\n",
        "assert np.allclose(\n",
        "    row_ma[[\"female_mean_salary\", \"male_mean_salary\", \"gap_m_minus_f\"]]\n",
        "    .astype(float)\n",
        "    .to_numpy(),\n",
        "    [75772.277, 75360.362, -411.915],\n",
        ")\n",
        "### END HIDDEN TESTS"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6accda04",
      "metadata": {},
      "source": [
        "### Q8 (7 pts) — Top earners per department [DEMO]\n",
        "\n",
        "_This question is for exploration purposes only. Everyone will receive 7 points. Be sure to run the cell._\n",
        "\n",
        "Create a DataFrame `top_earners` containing the **top 3** employees by `Total_Comp` within each `Department`.\n",
        "\n",
        "Keep these columns (at least):\n",
        "`Employee_ID, Name, Department, Salary, Annual_Bonus, Total_Comp`\n",
        "\n",
        "Sort results by `Department` then `Total_Comp` descending.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "902af3d4",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "q8_top_earners",
          "locked": false,
          "schema_version": 3,
          "solution": true
        }
      },
      "outputs": [],
      "source": [
        "cols = [\"Employee_ID\", \"Name\", \"Department\", \"Salary\", \"Annual_Bonus\", \"Total_Comp\"]\n",
        "tmp = df_cat[cols].sort_values([\"Department\", \"Total_Comp\"], ascending=[True, False])\n",
        "top_earners = tmp.groupby(\"Department\", group_keys=False).head(3).reset_index(drop=True)\n",
        "\n",
        "# Be sure to remove raise NotImplementedError()\n",
        "### BEGIN SOLUTION\n",
        "### END SOLUTION\n",
        "\n",
        "top_earners.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "571281ff",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "q8_top_earners_tests",
          "locked": true,
          "points": 7,
          "schema_version": 3,
          "solution": false
        }
      },
      "outputs": [],
      "source": [
        "assert isinstance(top_earners, pd.DataFrame)\n",
        "assert top_earners.groupby(\"Department\").size().max() <= 3\n",
        "for c in [\"Employee_ID\", \"Name\", \"Department\", \"Total_Comp\"]:\n",
        "    assert c in top_earners.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e41ed567",
      "metadata": {},
      "source": [
        "### Q9 (6 pts) — Correlation: Salary vs Performance [DEMO]\n",
        "\n",
        "_This question is for exploration purposes only. Everyone will receive 6 points. Be sure to run the cell._\n",
        "\n",
        "1. Compute overall Pearson correlation between `Salary` and `Performance_Score` as `corr_overall`.\n",
        "2. Compute per-department correlations as a Series `corr_by_dept` indexed by department.\n",
        "\n",
        "**Hints:**\n",
        "\n",
        "- Overall: `df_cat[[\"Salary\",\"Performance_Score\"]].corr()` and extract the correlation from the resulting covariance matrix.\n",
        "- By group: `groupby(\"Department\").apply(lambda g: g[\"Salary\"].corr(g[\"Performance_Score\"]))` lambda functions are further exploration and advanced topic.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b601d54",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "q9_correlations",
          "locked": false,
          "schema_version": 3,
          "solution": true
        }
      },
      "outputs": [],
      "source": [
        "corr_overall = df_cat[[\"Salary\", \"Performance_Score\"]].corr().iloc[0, 1]\n",
        "corr_by_dept = df_cat.groupby(\"Department\").apply(\n",
        "    lambda g: g[\"Salary\"].corr(g[\"Performance_Score\"])\n",
        ")\n",
        "print(f\"Overall correlation: {corr_overall:.3f}\")\n",
        "print(\"\\nCorelation by Department:\\n\")\n",
        "print(corr_by_dept)\n",
        "\n",
        "# Be sure to remove raise NotImplementedError()\n",
        "### BEGIN SOLUTION\n",
        "### END SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce8eaf00",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "q9_correlations_tests",
          "locked": true,
          "points": 6,
          "schema_version": 3,
          "solution": false
        }
      },
      "outputs": [],
      "source": [
        "assert isinstance(corr_by_dept, pd.Series)\n",
        "assert np.isclose(corr_overall, 0.075343)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8312050",
      "metadata": {},
      "source": [
        "### Q10 (6 pts) — Hiring trends: employees per year\n",
        "\n",
        "Create a DataFrame `hires_per_year` with columns:\n",
        "\n",
        "- `year`\n",
        "- `n_hired`\n",
        "\n",
        "derived from `Join_Date` (drop missing dates). Sorted by `year` ascending.\n",
        "\n",
        "**Hint:** `df[\"Join_Date\"].dt.year` and `value_counts().sort_index()`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60941cf4",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "q10_hires_per_year",
          "locked": false,
          "schema_version": 3,
          "solution": true
        }
      },
      "outputs": [],
      "source": [
        "# You can use a few intermediary/helper objects\n",
        "# years = ...\n",
        "# value_counts = ...\n",
        "# hires_per_year = ...\n",
        "\n",
        "### BEGIN SOLUTION\n",
        "years = df_cat[\"Join_Date\"].dropna().dt.year\n",
        "vc = years.value_counts().sort_index()\n",
        "hires_per_year = vc.rename_axis(\"year\").reset_index(name=\"n_hired\")\n",
        "### END SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06c02082",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "q10_hires_per_year_tests",
          "locked": true,
          "points": 6,
          "schema_version": 3,
          "solution": false
        }
      },
      "outputs": [],
      "source": [
        "assert isinstance(hires_per_year, pd.DataFrame)\n",
        "assert set([\"year\", \"n_hired\"]).issubset(hires_per_year.columns)\n",
        "### BEGIN HIDDEN TESTS\n",
        "assert np.isclose(hires_per_year[\"year\"].sum(), 28231), (\n",
        "    \"The values in column year are not accurate\"\n",
        ")\n",
        "assert hires_per_year.shape == (14, 2), (\n",
        "    \"The number of columns and rows is not as expected\"\n",
        ")\n",
        "assert np.isclose(hires_per_year[\"n_hired\"].sum(), 98013), \"n_hired is not accurate\"\n",
        "### END HIDDEN TESTS"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6aa708d",
      "metadata": {},
      "source": [
        "### Q11 (7 pts) — Overtime analysis by department [DEMO]\n",
        "\n",
        "_This question is for exploration purposes only. Everyone will receive the 7 points. Be sure to run the cell._\n",
        "\n",
        "Using `Overtime` from Q4, create `overtime_dept` indexed by `Department` with:\n",
        "\n",
        "- `avg_overtime`\n",
        "- `pct_overtime_workers` = percent of employees in the department with overtime > 0 (exclude missing Working_Hours)\n",
        "\n",
        "Sort by `avg_overtime` descending.\n",
        "\n",
        "**Hints:**\n",
        "\n",
        "- For percent: `(g[\"Overtime\"] > 0).mean() * 100` but watch missing values\n",
        "- Consider `dropna()` on Overtime for the percent denominator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff49fdf5",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "q11_overtime_dept",
          "locked": false,
          "schema_version": 3,
          "solution": true
        }
      },
      "outputs": [],
      "source": [
        "# In function definition what comes after : and -> signs (in parameters and after function)\n",
        "# are type hints. They simply remind you what type goes in the function and what type is returned.\n",
        "# Here g is pd.DataFrame type and the function returns a float type.\n",
        "def pct_overtime(g: pd.DataFrame) -> float:\n",
        "    s = g[\"Overtime\"].dropna()\n",
        "    if len(s) == 0:\n",
        "        return np.nan\n",
        "    return (s > 0).mean() * 100\n",
        "\n",
        "\n",
        "# Notice the use of lambda (advanced topic).\n",
        "overtime_dept = (\n",
        "    df_cat.groupby(\"Department\")\n",
        "    .apply(\n",
        "        lambda g: pd.Series(\n",
        "            {\n",
        "                \"avg_overtime\": g[\"Overtime\"].mean(),\n",
        "                \"pct_overtime_workers\": pct_overtime(g),\n",
        "            }\n",
        "        )\n",
        "    )\n",
        "    .sort_values(\"avg_overtime\", ascending=False)\n",
        ")\n",
        "\n",
        "# Be sure to remove raise NotImplementedError()\n",
        "### BEGIN SOLUTION\n",
        "### END SOLUTION\n",
        "\n",
        "overtime_dept"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f038df2",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "q11_overtime_dept_tests",
          "locked": true,
          "points": 7,
          "schema_version": 3,
          "solution": false
        }
      },
      "outputs": [],
      "source": [
        "assert isinstance(overtime_dept, pd.DataFrame)\n",
        "for c in [\"avg_overtime\", \"pct_overtime_workers\"]:\n",
        "    assert c in overtime_dept.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f33f5b4e",
      "metadata": {},
      "source": [
        "### Q12.1 (2 pts) — Education vs pay & performance\n",
        "\n",
        "**A solution for this problem is mostly implemented. You will finish the solution and provide a written answer to the quesiton.**\n",
        "\n",
        "We created a DataFrame `edu_summary` indexed by `Education` with:\n",
        "\n",
        "- `n`\n",
        "- `mean_salary`\n",
        "- `mean_perf`\n",
        "\n",
        "Sort this dataframe by `mean_salary` in descending order.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d60b0856",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "q12_edu_summary",
          "locked": false,
          "schema_version": 3,
          "solution": true
        }
      },
      "outputs": [],
      "source": [
        "edu_summary = df_cat.groupby(\"Education\").agg(\n",
        "    n=(\"Employee_ID\", \"count\"),\n",
        "    mean_salary=(\"Salary\", \"mean\"),\n",
        "    mean_perf=(\"Performance_Score\", \"mean\"),\n",
        ")\n",
        "### BEGIN SOLUTION\n",
        "edu_summary = edu_summary.sort_values(\"mean_salary\", ascending=False)\n",
        "### END SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8022fd4",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "q12_edu_summary_tests",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false
        }
      },
      "outputs": [],
      "source": [
        "assert isinstance(edu_summary, pd.DataFrame)\n",
        "for c in [\"n\", \"mean_salary\", \"mean_perf\"]:\n",
        "    assert c in edu_summary.columns, f\"Column {c} not found in edu_summary\"\n",
        "\n",
        "### BEGIN HIDDEN TESTS\n",
        "assert edu_summary[\"mean_salary\"].is_monotonic_decreasing, (\n",
        "    \"mean_salary is not sorted descending (non-increasing)\"\n",
        ")\n",
        "### END HIDDEN TESTS"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56fa6996",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "q12_edu_summary_task",
          "locked": false,
          "points": 4,
          "schema_version": 3,
          "solution": true
        }
      },
      "source": [
        "### Q12.2 (4 pts) - What are your observations from this table? Why do you think we're seeing this trend in data?\n",
        "\n",
        "_You may need to double-click this cell to edit._\n",
        "\n",
        "### BEGIN SOLUTION\n",
        "\n",
        "There is little difference between salary for educational groups. While such trend can very well exist in a real-world scenario, here it shows that our dataset is synthetic.\n",
        "The authors of dataset could have used stratified sampling to inject structure into the synthetic data and better mimic the real-world.\n",
        "\n",
        "### END SOLUTION\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4c51dab",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Part C — Visualization (25 points)\n",
        "\n",
        "### Q13 (8 pts) — Salary distribution by department (boxplot)\n",
        "\n",
        "Create a **single figure** showing a **boxplot** of `Salary` by `Department`.\n",
        "\n",
        "Requirements:\n",
        "\n",
        "- Use either OO-style or pyplot style.\n",
        "- Title: `\"Salary Distribution by Department\"`\n",
        "- X-axis label: `\"Department\"`\n",
        "- Y-axis label: `\"Salary\"`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca90fc80",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "q13_boxplot",
          "locked": false,
          "points": 8,
          "schema_version": 3,
          "solution": true
        }
      },
      "outputs": [],
      "source": [
        "# This is just a suggested layout using OO-style approach.\n",
        "# Feel free to use any other layout or pyplot approach.\n",
        "# fig_q13, ax = plt.subplots(figsize=(8, 4))\n",
        "\n",
        "### BEGIN SOLUTION\n",
        "fig_q13, ax = plt.subplots(figsize=(8, 4))\n",
        "# Drop missing salaries\n",
        "plot_df = df_cat.dropna(subset=[\"Salary\", \"Department\"])\n",
        "# Prepare data grouped by department\n",
        "depts = plot_df[\"Department\"].astype(str).unique()\n",
        "data = [\n",
        "    plot_df.loc[plot_df[\"Department\"].astype(str) == d, \"Salary\"].to_numpy()\n",
        "    for d in depts\n",
        "]\n",
        "ax.boxplot(data, tick_labels=depts)\n",
        "ax.set_title(\"Salary Distribution by Department\")\n",
        "ax.set_xlabel(\"Department\")\n",
        "ax.set_ylabel(\"Salary\")\n",
        "ax.tick_params(axis=\"x\", rotation=30)\n",
        "fig_q13.tight_layout()\n",
        "### END SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddf37071",
      "metadata": {},
      "source": [
        "### Q14 (9 pts) — Trend plot: hires per year\n",
        "\n",
        "Using `hires_per_year` from Q10, plot a line chart of `n_hired` vs `year`.\n",
        "\n",
        "Requirements:\n",
        "\n",
        "- Use **OO-style** (`fig, ax = plt.subplots()`)\n",
        "- Markers visible on points\n",
        "- Title: `\"Employees Hired per Year\"`\n",
        "- X-axis label: `\"Year\"`\n",
        "- Y-axis label: `\"Number Hired\"`\n",
        "\n",
        "Store the Axes as `ax_q14`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31812cfe",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "q14_hires_plot",
          "locked": false,
          "points": 7,
          "schema_version": 3,
          "solution": true
        }
      },
      "outputs": [],
      "source": [
        "### BEGIN SOLUTION\n",
        "fig, ax_q14 = plt.subplots(figsize=(7, 4))\n",
        "ax_q14.plot(hires_per_year[\"year\"], hires_per_year[\"n_hired\"], marker=\"o\")\n",
        "ax_q14.set_title(\"Employees Hired per Year\")\n",
        "ax_q14.set_xlabel(\"Year\")\n",
        "ax_q14.set_ylabel(\"Number Hired\")\n",
        "ax_q14.grid(True, alpha=0.3)\n",
        "fig.tight_layout()\n",
        "### END SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70387267",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "q14_hires_plot_tests",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "### BEGIN HIDDEN TESTS\n",
        "from matplotlib.axes import Axes\n",
        "\n",
        "assert isinstance(ax_q14, Axes), (\n",
        "    \"There must exist a matplotlib Axes object named ax_q14\"\n",
        ")\n",
        "### END HIDDEN TESTS"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adc87636",
      "metadata": {},
      "source": [
        "### Q15 (8 pts) — Relationship plot: Salary vs Performance, colored by department\n",
        "\n",
        "Create a scatter plot of `Salary` vs `Performance_Score`, with points colored by `Department`.\n",
        "\n",
        "Requirements:\n",
        "\n",
        "- Use Matplotlib (OO-style might be the better choice here)\n",
        "- Include a legend with department names\n",
        "- Title: `\"Salary vs Performance (by Department)\"`\n",
        "- X-axis label: `\"Salary\"`\n",
        "- Y-axis label: `\"Performance Score\"`\n",
        "\n",
        "Store the figure as `fig_q15`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "062aa793",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "q15_scatter_by_dept",
          "locked": false,
          "points": 8,
          "schema_version": 3,
          "solution": true
        }
      },
      "outputs": [],
      "source": [
        "### BEGIN SOLUTION\n",
        "fig_q15, ax = plt.subplots(figsize=(7, 5))\n",
        "plot_df = df_cat.dropna(subset=[\"Salary\", \"Performance_Score\", \"Department\"])\n",
        "\n",
        "for dept, g in plot_df.groupby(\"Department\"):\n",
        "    ax.scatter(g[\"Salary\"], g[\"Performance_Score\"], label=str(dept), alpha=0.7)\n",
        "\n",
        "ax.set_title(\"Salary vs Performance (by Department)\")\n",
        "ax.set_xlabel(\"Salary\")\n",
        "ax.set_ylabel(\"Performance Score\")\n",
        "ax.legend(title=\"Department\", loc=\"best\")\n",
        "ax.grid(True, alpha=0.3)\n",
        "fig_q15.tight_layout()\n",
        "### END SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9ea3650",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Submission checklist\n",
        "\n",
        "- Restart kernel, run all cells top-to-bottom.\n",
        "- Ensure **no errors**.\n",
        "- Save notebook and submit the `.ipynb` file.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "psych-723 (3.12.12)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "nbgrader": {
      "assignment_id": "hw2",
      "course_id": "psyc723",
      "notebook_id": "hw2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}