{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9aed158a",
      "metadata": {},
      "source": [
        "# Homework: KNN Classification for Employee Attrition\n",
        "\n",
        "**Total: 120 points** • **Questions: 10**\n",
        "\n",
        "This homework uses one dataset: **ibm_attrition** (CSV). You will practice:\n",
        "\n",
        "- Working with a close-to-reality HRIS dataset addressing a recurrent HR problem: predicting employee attrition based on a rich features.\n",
        "- Feature scaling\n",
        "- Feature Selection\n",
        "- Splitting data into train/test sets\n",
        "- Developing understanding of where test split should and SHOULD NOT be used to prevent test signal leakage\n",
        "- Fitting a KNN classifer for to predict employees that are at the most risk of leaving the company\n",
        "- Evaluating the model performance against test split and finding optimal KNN parameters to maximize evaluation metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f28418f2",
      "metadata": {},
      "source": [
        "## Instructions (important)\n",
        "\n",
        "- Do **not** hard-code answers; compute them from the data.\n",
        "- Some questions ask you to create specific variables. **Name them exactly** as requested.\n",
        "- If you're using Google Colab, you need to upload the downloaded dataset to your Colab Files section.\n",
        "- For much of this homework, your solution will be self-guided. You may refer back to the lecture notebook for steps you need to follow and the order by which to follow those steps.\n",
        "- Following guidance from the lecture will result in an **acceptable solution**. But for a **perfect solution**, further experimentation and exploration is needed.\n",
        "- You may use additional tools and functions from `sklearn` but using any other libraries besides the ones provided in this notebook is **strictly prohibited**.\n",
        "\n",
        "### Grading\n",
        "\n",
        "This notebook uses autograding:\n",
        "\n",
        "- The major part of the grade for this assignment comes from **Q7** but this question also depends on Q6 and others. Make sure you budget your effort proportionally.\n",
        "- **Answer cells** are marked as `# YOUR CODE HERE` or `# YOUR ANSWER HERE` and will be graded.\n",
        "- Remove `raise NotImplementedError()` once you start working on a solution.\n",
        "- **Do not** edit the content of LOCKED cells.\n",
        "- **Do not** attempt to DELETE or MOVE any of the included cells.\n",
        "- You MAY ADD **additional code cells** to experiment. You may remove these added blocks once you're done with your work. But if you intend to show your work (graph, summaries etc.) or another cell depends on the content of the created cell, you may keep it.\n",
        "- Besides the sanity check tests visible to you, we might use additional rigorous hidden tests that are only available after submission. Double-check your work for accuracy and do not rely on sanity checks.\n",
        "- This notebook contains metadata for tracking. Do not share your notebook or create a new notebook from scratch.\n",
        "- If anything breaks, save your work and download a fresh copy of the notebook from Canvas. You can copy your finished code and insert that block by block into the new copy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "id": "487007f6",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "setup",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# Setup\n",
        "\n",
        "import hashlib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    f1_score,\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
        "\n",
        "RANDOM_STATE = 2025\n",
        "\n",
        "# Plot style\n",
        "sns.set(style=\"whitegrid\")\n",
        "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
        "\n",
        "\n",
        "def dataframe_digest(df: pd.DataFrame) -> str:\n",
        "    \"\"\"\n",
        "    Returns hexdigest of the hashed value of a given pands dataframe.\n",
        "    \"\"\"\n",
        "    row_hashes = pd.util.hash_pandas_object(df, index=True)\n",
        "    h = hashlib.sha256()\n",
        "    h.update(row_hashes.values.tobytes())\n",
        "    return h.hexdigest()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be82f9f6",
      "metadata": {},
      "source": [
        "---\n",
        "# Data Preprocessing\n",
        "\n",
        "We are using the `ibm_attrition.csv` for this homework.\n",
        "\n",
        "We first form and process our target vector `y` and feature matrix `X`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "id": "ebac24e0",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "load",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of df: (1470, 32)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Attrition</th>\n",
              "      <th>BusinessTravel</th>\n",
              "      <th>DailyRate</th>\n",
              "      <th>Department</th>\n",
              "      <th>DistanceFromHome</th>\n",
              "      <th>Education</th>\n",
              "      <th>EducationField</th>\n",
              "      <th>EnvironmentSatisfaction</th>\n",
              "      <th>Gender</th>\n",
              "      <th>...</th>\n",
              "      <th>PerformanceRating</th>\n",
              "      <th>RelationshipSatisfaction</th>\n",
              "      <th>StockOptionLevel</th>\n",
              "      <th>TotalWorkingYears</th>\n",
              "      <th>TrainingTimesLastYear</th>\n",
              "      <th>WorkLifeBalance</th>\n",
              "      <th>YearsAtCompany</th>\n",
              "      <th>YearsInCurrentRole</th>\n",
              "      <th>YearsSinceLastPromotion</th>\n",
              "      <th>YearsWithCurrManager</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>41</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>1102</td>\n",
              "      <td>Sales</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Life Sciences</td>\n",
              "      <td>2</td>\n",
              "      <td>Female</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>49</td>\n",
              "      <td>No</td>\n",
              "      <td>Travel_Frequently</td>\n",
              "      <td>279</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>Life Sciences</td>\n",
              "      <td>3</td>\n",
              "      <td>Male</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>37</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>1373</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>Other</td>\n",
              "      <td>4</td>\n",
              "      <td>Male</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>No</td>\n",
              "      <td>Travel_Frequently</td>\n",
              "      <td>1392</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>Life Sciences</td>\n",
              "      <td>4</td>\n",
              "      <td>Female</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>27</td>\n",
              "      <td>No</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>591</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Medical</td>\n",
              "      <td>1</td>\n",
              "      <td>Male</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 32 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Age Attrition     BusinessTravel  DailyRate              Department  \\\n",
              "0   41       Yes      Travel_Rarely       1102                   Sales   \n",
              "1   49        No  Travel_Frequently        279  Research & Development   \n",
              "2   37       Yes      Travel_Rarely       1373  Research & Development   \n",
              "3   33        No  Travel_Frequently       1392  Research & Development   \n",
              "4   27        No      Travel_Rarely        591  Research & Development   \n",
              "\n",
              "   DistanceFromHome  Education EducationField  EnvironmentSatisfaction  \\\n",
              "0                 1          2  Life Sciences                        2   \n",
              "1                 8          1  Life Sciences                        3   \n",
              "2                 2          2          Other                        4   \n",
              "3                 3          4  Life Sciences                        4   \n",
              "4                 2          1        Medical                        1   \n",
              "\n",
              "   Gender  ...  PerformanceRating  RelationshipSatisfaction  StockOptionLevel  \\\n",
              "0  Female  ...                  3                         1                 0   \n",
              "1    Male  ...                  4                         4                 1   \n",
              "2    Male  ...                  3                         2                 0   \n",
              "3  Female  ...                  3                         3                 0   \n",
              "4    Male  ...                  3                         4                 1   \n",
              "\n",
              "  TotalWorkingYears  TrainingTimesLastYear WorkLifeBalance  YearsAtCompany  \\\n",
              "0                 8                      0               1               6   \n",
              "1                10                      3               3              10   \n",
              "2                 7                      3               3               0   \n",
              "3                 8                      3               3               8   \n",
              "4                 6                      3               3               2   \n",
              "\n",
              "   YearsInCurrentRole  YearsSinceLastPromotion YearsWithCurrManager  \n",
              "0                   4                        0                    5  \n",
              "1                   7                        1                    7  \n",
              "2                   0                        0                    0  \n",
              "3                   7                        3                    0  \n",
              "4                   2                        2                    2  \n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"ibm_attrition.csv\")\n",
        "\n",
        "# Dropping columns with no significant contribution.\n",
        "df.drop(columns=[\"EmployeeCount\", \"EmployeeNumber\", \"StandardHours\"], inplace=True)\n",
        "\n",
        "print(f\"Shape of df: {df.shape}\")\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "id": "21218b46",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "data-hash",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "assert (\n",
        "    dataframe_digest(df)\n",
        "    == \"3e7e5b96a1eacc81f5b775506e69ef95cd3476d75bf6e0123dec51f823bc06db\"\n",
        "), (\n",
        "    \"Dataframe digest doesn't match. Either your data file is corruputed or you're using a differnt version of pandas library.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17906172",
      "metadata": {},
      "source": [
        "### Q1 (3 pts) – Manual Encoding\n",
        "\n",
        "Use custom python dictionary to encode the target variable `\"Attrition\"`. No should be mapped to 0 and Yes should be mapped to 1. Assign the mapped object to a variable named `y`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "id": "bec64f4d",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "attrition-counts",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Attrition\n",
              "No     1233\n",
              "Yes     237\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[\"Attrition\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "id": "0d5c2dd1",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "q1_1",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# y = ...\n",
        "### BEGIN SOLUTION\n",
        "label_map = {\"No\": 0, \"Yes\": 1}\n",
        "y = df[\"Attrition\"].map(label_map)\n",
        "### END SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "id": "b56761d9",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "q1_2",
          "locked": true,
          "points": 3,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "assert isinstance(y, pd.core.series.Series), \"y should be a pandas Series object\"\n",
        "### BEGIN HIDDEN TESTS\n",
        "assert set(np.unique(y)) == {0, 1}\n",
        "assert y.shape == (1470,)\n",
        "### END HIDDEN TESTS"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc48658d",
      "metadata": {},
      "source": [
        "### Q2 (2 pts) – Using LabelEncoder\n",
        "\n",
        "Now perform the same encoding of label variable using `LabelEncoder()` from scikit-learn. Assign the resulting variable to `y2` The resulting variable from this question and previous question should be numerically equivalent but they may have different types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "id": "3718f087",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "q2_1",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "target_encoder = LabelEncoder()\n",
        "# y2 = ...\n",
        "### BEGIN SOLUTION\n",
        "y2 = target_encoder.fit_transform(df[\"Attrition\"])\n",
        "### END SOLUTION\n",
        "# df[\"Attrition\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "id": "cfe21ea6",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "q2_2",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "assert isinstance(y2, np.ndarray), \"y2 should be Numpy ndarray object\"\n",
        "### BEGIN HIDDEN TESTS\n",
        "assert y2.shape == (1470,)\n",
        "### END HIDDEN TESTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "id": "4c0d0abd",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-726c6a055f07",
          "locked": true,
          "points": 10,
          "schema_version": 3,
          "solution": false
        }
      },
      "outputs": [],
      "source": [
        "assert np.isclose(sum(y), sum(y2), atol=0.0001), (\n",
        "    \"y and y2 should be numerically similar\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cd7284d",
      "metadata": {},
      "source": [
        "After we're done processing y vector, we can form our feature matrix `X`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "id": "cb4fa041",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-9c51840f5fac",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "outputs": [],
      "source": [
        "X = df.drop(columns=\"Attrition\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fc16e32",
      "metadata": {},
      "source": [
        "## Categorical vs. Numerical Features\n",
        "\n",
        "Here we have to pursue different approaches for numerical and categorical columns. In the lecture we covered dealing with numerical features which we simply standardize. Here we remove the categorical features since numerical values provide good enough decision boundaries.\n",
        "\n",
        "> **Advanced Topic:**  \n",
        "> For categorical features we need to employ an encoding scheme (remember we also encoded our binary target y). But different encodoing schemes are used for features. One of the most popular schemes is one-hot-encoding and sklearn provides a `OneHotEncoder()` class for this purpose. This is an advanced topic that you may explore on your own but working with this encoder is somewhat similar to `StandardScaler()` class.  \n",
        "> In the starter code below, we are simply dropping the categorical columns so we don't have to deal with them. If you decide to include them back in, you may do that in a future block of code. Remember that your notebook should execute from top to bottom, so make sure you're not accidentally overwriting your own code in lower blocks.  \n",
        "> The object `X` will remain untouched which you can use to slice for categorical features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "id": "f97270b4",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cat_num_feat",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "categorical columns that will be dropped:\n",
            "['BusinessTravel', 'Department', 'EducationField', 'Gender', 'JobRole', 'MaritalStatus', 'Over18', 'OverTime']\n",
            "\n",
            "\n",
            "X_num shape: (1470, 32)\n"
          ]
        }
      ],
      "source": [
        "# Here we separate out the categorical and numerical feature names.\n",
        "\n",
        "numerical_feats = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
        "# You may use the categorical feature names stored in this object for\n",
        "# indexing if you choose to include them back in.\n",
        "categorical_feats = X.select_dtypes(include=\"object\").columns.tolist()\n",
        "\n",
        "print(\"categorical columns that will be dropped:\")\n",
        "print(categorical_feats)\n",
        "# We continue working on X_num while leaving X on its own.\n",
        "X_num = X.drop(columns=categorical_feats)\n",
        "print(\"\\n\")\n",
        "print(f\"X_num shape: {df.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "020cc921",
      "metadata": {},
      "source": [
        "# Splitting and Scaling Sets\n",
        "\n",
        "Pay attention to the order of operations here. We first split the data, then work on scaling both splits using parameters obtained **ONLY** from train split.  \n",
        "Since KNN relies on distance metrics, it is very important to have features on the same scale. This is why we must choose a scaling scheme like standardization.  \n",
        "The target `y` does not need scaling. Why?\n",
        "\n",
        "> **Advanced Topic:**  \n",
        "> If you choose to explore using categorical features, keep note of another complication.  \n",
        "> You must split first, then scale the numerical features while encoding the categorical features.  \n",
        "> Then you can concatenated them back into a unified feature matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "id": "e1722714",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "split",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# Choice of random_state which we hardcoded in top of our notebook, can change your computations.\n",
        "# We use this for code reproducibility.\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_num, y, test_size=0.25, random_state=RANDOM_STATE, stratify=y\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72c640a4",
      "metadata": {},
      "source": [
        "## Q3 (4 pts) – Manual Feature Scaling\n",
        "\n",
        "Scale the train and test splits of feature matrix X manually. Do not use `sklearn` provided methods here. Store the results in `X_train_scaled` and `X_test_scaled` objects respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "id": "7024eac7",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "q3_1",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# X_train_scaled = ...\n",
        "# X_test_scaled = ...\n",
        "\n",
        "### BEGIN SOLUTION\n",
        "train_mean = X_train.mean(axis=0)\n",
        "train_std = X_train.std(axis=0)\n",
        "\n",
        "X_train_scaled = (X_train - train_mean) / train_std\n",
        "X_test_scaled = (X_test - train_mean) / train_std\n",
        "### END SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "id": "c9e02203",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "q3_2",
          "locked": true,
          "points": 4,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "assert isinstance(X_train_scaled, pd.core.frame.DataFrame), (\n",
        "    \"X_train_scaled should be a pandas DataFrame\"\n",
        ")\n",
        "assert isinstance(X_test_scaled, pd.core.frame.DataFrame), (\n",
        "    \"X_test_scaled should be a pandas DataFrame\"\n",
        ")\n",
        "\n",
        "### BEGIN HIDDEN TESTS\n",
        "assert np.allclose(X_train_scaled.mean(axis=0), 0)\n",
        "assert np.allclose(X_train_scaled.std(axis=0), 1)\n",
        "assert not np.allclose(X_test_scaled.mean(axis=0), 0)\n",
        "assert not np.allclose(X_test_scaled.std(axis=0), 1)\n",
        "assert X_train_scaled.shape == (1102, 23)\n",
        "assert X_test_scaled.shape == (368, 23)\n",
        "### END HIDDEN TESTS"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72ad0cba",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "q4_1",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": true
        }
      },
      "source": [
        "## Q4 (4 pts) – Examining Feature Scaling\n",
        "\n",
        "In the code block below show if `X_train_scaled` and `X_test_scaled` are standardized."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "id": "58741b64",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "q4_2",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "### BEGIN SOLUTION\n",
        "### END SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "962fa1fb",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "q4_3",
          "locked": false,
          "points": 2,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "Are these two feature sets standardized? Explain why.\n",
        "\n",
        "### BEGIN SOLUTION\n",
        "The `X_train_scaled` is scaled but `X_test_scaled` is not fully scaled because we used parameters obtained from the train split to sclae the test split. This is expected.\n",
        "### END SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc2ace35",
      "metadata": {},
      "source": [
        "## Q5 (2 pts) – Feature Scaling Using StandardScaler\n",
        "\n",
        "Now let's scale both train and test X splits this time using provided method from sklearn.  \n",
        "- Save the output to `X_train_scaled_s` and `X_test_scaled_s` object.  \n",
        "- The results should be numerically equivalent to those you obtained manually in a previous question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "id": "86f0bf37",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "q5_1",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "# X_train_scaled_s = ...\n",
        "# X_test_scaled_s = ...\n",
        "### BEGIN SOLUTION\n",
        "X_train_scaled_s = scaler.fit_transform(X_train)\n",
        "X_test_scaled_s = scaler.transform(X_test)\n",
        "### END SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3e4667b",
      "metadata": {},
      "source": [
        "> **Advanced Topic:**\n",
        "> You can examine the scaler object to see the feature names.\n",
        "> These are stored in the object after .fit() is called on StandardScaler instance and a dataset is passed to it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "id": "6a835f7d",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "q5_2",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "outputs": [],
      "source": [
        "assert isinstance(X_train_scaled_s, np.ndarray), (\n",
        "    \"X_train_scaled_s should be a numpy ndarray type\"\n",
        ")\n",
        "assert isinstance(X_test_scaled_s, np.ndarray), (\n",
        "    \"X_test_scaled_s should be a numpy ndarray type\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "id": "3e22999b",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "q5_3",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Age', 'DailyRate', 'DistanceFromHome', 'Education',\n",
              "       'EnvironmentSatisfaction', 'HourlyRate', 'JobInvolvement',\n",
              "       'JobLevel', 'JobSatisfaction', 'MonthlyIncome', 'MonthlyRate',\n",
              "       'NumCompaniesWorked', 'PercentSalaryHike', 'PerformanceRating',\n",
              "       'RelationshipSatisfaction', 'StockOptionLevel',\n",
              "       'TotalWorkingYears', 'TrainingTimesLastYear', 'WorkLifeBalance',\n",
              "       'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion',\n",
              "       'YearsWithCurrManager'], dtype=object)"
            ]
          },
          "execution_count": 141,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scaler.get_feature_names_out()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "id": "f56bd0ef",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "q5_4",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "### BEGIN HIDDEN TESTS\n",
        "assert np.allclose(X_train_scaled.to_numpy(), X_train_scaled_s, atol=0.01)\n",
        "assert np.allclose(X_train_scaled_s.mean(axis=0), 0)\n",
        "assert np.allclose(X_train_scaled_s.std(axis=0), 1)\n",
        "assert not np.allclose(X_test_scaled_s.mean(axis=0), 0)\n",
        "assert not np.allclose(X_test_scaled_s.std(axis=0), 1)\n",
        "### END HIDDEN TESTS"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1538620f",
      "metadata": {},
      "source": [
        "---\n",
        "# Feature Selection and Model Fitting"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "743c4c1c",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "q6_1",
          "locked": false,
          "points": 6,
          "schema_version": 3,
          "solution": false,
          "task": true
        }
      },
      "source": [
        "## Q6 (8 pts) – Feature Selection\n",
        "\n",
        "Here you need to perform a few steps to filter and select the features that provide the best model.  \n",
        "- What constitutes a good model is usually a combination of explainability as well as the performance of predictions.  \n",
        "- While explaining the process is important, for the purpose of this assignment we aim to maximize the prediction performance of the model.  \n",
        "- Feature selection is usually a cyclic and iterative approach. You first select some features based on what you see from the data or theories you have about their predictive power. Then you fit the model. Then you come back to drop or add other features. Rinse and repeat.  \n",
        "- Model fitting will follow this step.\n",
        "\n",
        "> You can explain your process in the provided block below.  \n",
        "> You may also use additional code blocks for tables, summaries, graphs etc.  \n",
        "> When done, you'd need to store your feature names in the provided `selected_features` list."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b30be9b",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "q6_2",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "Explanations:\n",
        "\n",
        "### BEGIN SOLUTION\n",
        "### END SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "id": "038c2b3b",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "q6_3",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# selected_features = [\n",
        "#     \"Age\",\n",
        "#     \"DistanceFromHome\",\n",
        "#     \"JobInvolvement\",\n",
        "# ]\n",
        "\n",
        "### BEGIN SOLUTION\n",
        "selected_features = [\n",
        "    \"Age\",\n",
        "    \"DistanceFromHome\",\n",
        "    \"JobInvolvement\",\n",
        "    \"JobLevel\",\n",
        "    \"JobSatisfaction\",\n",
        "    \"MonthlyIncome\",\n",
        "    \"StockOptionLevel\",\n",
        "    \"YearsWithCurrManager\",\n",
        "    \"PerformanceRating\",\n",
        "    \"RelationshipSatisfaction\",\n",
        "    \"WorkLifeBalance\",\n",
        "]\n",
        "### END SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "id": "5dfc3501",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "q6_4",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false
        }
      },
      "outputs": [],
      "source": [
        "assert isinstance(selected_features, list), \"selected_features must be a list\"\n",
        "assert len(selected_features) >= 3, \"You should at least select 3 features\"\n",
        "assert all(isinstance(el, str) for el in selected_features), (\n",
        "    \"All elements of selected_features should be strings.\"\n",
        ")\n",
        "\n",
        "### BEGIN HIDDEN TESTS\n",
        "assert set(selected_features).issubset(set(X_train_scaled.columns))\n",
        "assert len(set(selected_features)) == len(selected_features)\n",
        "assert \"Attrition\" not in selected_features\n",
        "### END HIDDEN TESTS"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d16799b",
      "metadata": {},
      "source": [
        "## Q7 (80 pts) – Model Fitting and Evaluation\n",
        "\n",
        "Now it's time to train your model.  \n",
        "- Besides k `n_neighbors`, our classifier has other hyper-parameters as well which you may choose to tweak.  \n",
        "- Remember this is an iterative process. You pick some hyper-paramerts, fit the model, evaluate, tweak parameters, fit and evaluate.\n",
        "- The other part of the iteration is feature selection. You may need to go back to that many times to fit a great model.\n",
        "\n",
        "**Grading:**  \n",
        "- You must optimize for your model's accuracy and F1 score (F1 for attrition class)  \n",
        "- This question is worth 80/120 of your total score for this assignment\n",
        "- 50/80 comes from F1 score for attrition class\n",
        "\n",
        "| F1 Score     | Points |\n",
        "| ------------ | ------ |\n",
        "| >= 0.36      | 50     |\n",
        "| 0.33 - 0.359 | 47     |\n",
        "| 0.30 - 0.329 | 42     |\n",
        "| 0.25 - 0.299 | 35     |\n",
        "| 0.20 - 0.249 | 30     |\n",
        "| 0.12 - 0.199 | 20     |\n",
        "| 0.06 - 0.119 | 10     |\n",
        "| < 0.06       | 0      |\n",
        "\n",
        "- 30/80 comes from the overall accuracy\n",
        "\n",
        "| Accuracy     | Points |\n",
        "| ------------ | ------ |\n",
        "| >= 0.85      | 30     |\n",
        "| 0.83 - 0.849 | 22     |\n",
        "| 0.81 - 0.829 | 15     |\n",
        "| < 0.81       | 0      |\n",
        "\n",
        "\n",
        "> **Note:**  \n",
        "> We use your fitted model named `model` to grade your work.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "id": "06ad7e92",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "q7_1",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score for Attrition Class: 0.063\n",
            "Overall Accuracy: 0.840\n"
          ]
        }
      ],
      "source": [
        "# A base solution is provided here.\n",
        "# Slicing our feature sets to only include our selected_features\n",
        "X_train_retained = X_train_scaled[selected_features]\n",
        "X_test_retained = X_test_scaled[selected_features]\n",
        "\n",
        "# You can supply different parameters to metric, weights, and p arguments of the classifier\n",
        "# to override the default values. Some of these might improve evaluation metrics\n",
        "# Defining the model\n",
        "model = KNeighborsClassifier(n_neighbors=25)\n",
        "# Fitting to train set\n",
        "model.fit(X_train_retained, y_train)\n",
        "# Making predictions\n",
        "y_pred = model.predict(X_test_retained)\n",
        "\n",
        "# Calculating average accuracy and F1 score for attrition class.\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"F1 Score for Attrition Class: {f1:.3f}\")\n",
        "print(f\"Overall Accuracy: {accuracy:.3f}\")\n",
        "\n",
        "# Most of the base solution is implemented for you.\n",
        "# You can simply remove the error code and run.\n",
        "\n",
        "### BEGIN SOLUTION\n",
        "### END SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4abb3cce",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "q7_2",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "outputs": [],
      "source": [
        "assert isinstance(model, KNeighborsClassifier), (\n",
        "    \"model must be a sklearn KNeighborsClassifier.\"\n",
        ")\n",
        "assert hasattr(model, \"classes_\"), \"Model does not appear fitted (missing classes_).\"\n",
        "assert hasattr(model, \"n_features_in_\"), (\n",
        "    \"Model does not appear fitted (missing n_features_in_).\"\n",
        ")\n",
        "assert X_train_retained.shape[1] == len(selected_features), (\n",
        "    \"Ensure you are using the right feature subset for model training.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fa1ada1",
      "metadata": {},
      "source": [
        "> **DO NOT delete the following empty cells. They contain your grading mechanism!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "id": "c914db86",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "q7_3",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The f1 score: 10\n",
            "The accuracy score: 22\n",
            "The total score for this question: 32\n"
          ]
        }
      ],
      "source": [
        "### BEGIN HIDDEN TESTS\n",
        "def f1_points(f1: float) -> int:\n",
        "    f1 = float(f1)\n",
        "    if f1 >= 0.36:\n",
        "        return 50\n",
        "    elif 0.33 <= f1 < 0.36:\n",
        "        return 47\n",
        "    elif 0.30 <= f1 < 0.33:\n",
        "        return 42\n",
        "    elif 0.25 <= f1 < 0.30:\n",
        "        return 35\n",
        "    elif 0.20 <= f1 < 0.25:\n",
        "        return 30\n",
        "    elif 0.12 <= f1 < 0.20:\n",
        "        return 20\n",
        "    elif 0.06 <= f1 < 0.12:\n",
        "        return 10\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n",
        "def accuracy_points(acc: float) -> int:\n",
        "    acc = float(acc)\n",
        "    if acc >= 0.85:\n",
        "        return 30\n",
        "    elif 0.83 <= acc < 0.85:\n",
        "        return 22\n",
        "    elif 0.81 <= acc < 0.83:\n",
        "        return 15\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n",
        "y_pred = model.predict(X_test_retained)\n",
        "\n",
        "f1s = f1_score(y_test, y_pred)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "assert 0.0 <= f1s <= 1.0, \"F1 out of range.\"\n",
        "assert 0.0 <= acc <= 1.0, \"Accuracy out of range.\"\n",
        "\n",
        "f1v = f1_points(f1s)\n",
        "acv = accuracy_points(acc)\n",
        "total_score = acv + f1v\n",
        "print(f\"The f1 score: {f1v}\")\n",
        "print(f\"The accuracy score: {acv}\")\n",
        "print(f\"The total score for this question: {total_score}\")\n",
        "### END HIDDEN TESTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "id": "6cce2831",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "q7_4",
          "locked": true,
          "points": 20,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "### BEGIN HIDDEN TESTS\n",
        "assert X_test_retained.shape[0] == 368\n",
        "assert y_test.shape[0] == 368\n",
        "assert model.n_samples_fit_ == X_train_retained.shape[0]\n",
        "assert np.allclose(np.asarray(model._fit_X), np.asarray(X_train_retained))\n",
        "assert np.array_equal(np.asarray(model._y).ravel(), np.asarray(y_train).ravel())\n",
        "### END HIDDEN TESTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5518b4e5",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "q7_5",
          "locked": true,
          "points": 20,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "### BEGIN HIDDEN TESTS\n",
        "assert total_score >= 40\n",
        "### END HIDDEN TESTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c02bf74",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "q7_6",
          "locked": true,
          "points": 20,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "### BEGIN HIDDEN TESTS\n",
        "assert total_score >= 60\n",
        "### END HIDDEN TESTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f20e139a",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "q7_7",
          "locked": true,
          "points": 20,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "### BEGIN HIDDEN TESTS\n",
        "assert 75 < total_score >= 80\n",
        "### END HIDDEN TESTS"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87d73aac",
      "metadata": {},
      "source": [
        "> Hints for getting to 100% score:\n",
        "> - Look for clues of why F1 score is not performing well.\n",
        "> - Pay attention to relationship between accuracy and F1 score. Is there a way to improve one without sacrificing the other?\n",
        "> - Look for other resources and signals in dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1db5e4a0",
      "metadata": {},
      "source": [
        "---\n",
        "# Predictions and Visualizations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8efead73",
      "metadata": {},
      "source": [
        "## Q8 (6 pts) – Instance Prediction\n",
        "\n",
        "Imagine this scenario:  \n",
        "Our model is trained and fully deployed to our production environment. HR team sends us a list of employees and asks us to determine whether they are likely to leave the company. The managers of these employees have determined that they might be on the verge of callig in quits!  \n",
        "You look at the list and see `John`. John is your buddy and he has complained about the work many times to you and said he's looking for work elsewhere.  \n",
        "Here is what HRIS API call returns for John. Use this data and make a prediction using your model.\n",
        "\n",
        "Save your model output to an object named `john_class`\n",
        "\n",
        "> **Hint:**  \n",
        "> This is a dictionary object (similar to what most API calls can return). How can you pass this to `.predict()` method from your model instance?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3eacd23",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "q8_1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "john = {\n",
        "    \"Age\": 30,\n",
        "    \"BusinessTravel\": \"Travel_Frequently\",\n",
        "    \"DailyRate\": 109,\n",
        "    \"Department\": \"Research & Development\",\n",
        "    \"DistanceFromHome\": 5,\n",
        "    \"Education\": 3,\n",
        "    \"EducationField\": \"Medical\",\n",
        "    \"EnvironmentSatisfaction\": 2,\n",
        "    \"Gender\": \"Female\",\n",
        "    \"HourlyRate\": 60,\n",
        "    \"JobInvolvement\": 3,\n",
        "    \"JobLevel\": 1,\n",
        "    \"JobRole\": \"Laboratory Technician\",\n",
        "    \"JobSatisfaction\": 2,\n",
        "    \"MaritalStatus\": \"Single\",\n",
        "    \"MonthlyIncome\": 2422,\n",
        "    \"MonthlyRate\": 25725,\n",
        "    \"NumCompaniesWorked\": 0,\n",
        "    \"Over18\": \"Y\",\n",
        "    \"OverTime\": \"No\",\n",
        "    \"PercentSalaryHike\": 17,\n",
        "    \"PerformanceRating\": 3,\n",
        "    \"RelationshipSatisfaction\": 1,\n",
        "    \"StockOptionLevel\": 0,\n",
        "    \"TotalWorkingYears\": 4,\n",
        "    \"TrainingTimesLastYear\": 3,\n",
        "    \"WorkLifeBalance\": 3,\n",
        "    \"YearsAtCompany\": 3,\n",
        "    \"YearsInCurrentRole\": 2,\n",
        "    \"YearsSinceLastPromotion\": 1,\n",
        "    \"YearsWithCurrManager\": 2,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b87ff81b",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "q8_2",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# This is a suggestion, there are many ways to read in this datapoint.\n",
        "\n",
        "# j_df = ... # First create a DataFrame from john\n",
        "# j_num = ... # Then slice using numerical feature (we have this in the notebook)\n",
        "# j_scaled = ... # Then scale using your previous scaler object\n",
        "# j_scaled_df = ... # Then turn back into a DataFrame\n",
        "# j_selected = ... # Filter by your selected features\n",
        "# john_class = model.predict(...) # Finally make a prediction\n",
        "\n",
        "### BEGIN SOLUTION\n",
        "j_df = pd.DataFrame([john])\n",
        "j_num = j_df[numerical_feats]\n",
        "j_scaled = scaler.transform(j_num)\n",
        "j_scaled_df = pd.DataFrame(j_scaled, columns=numerical_feats)\n",
        "j_selected = j_scaled_df[selected_features]\n",
        "john_class = model.predict(j_selected)[0]\n",
        "### END SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac9a150a",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "q8_3",
          "locked": true,
          "points": 6,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "assert isinstance(john_class, (np.int64, np.int32, int, np.ndarray)), (\n",
        "    \"john_class should be either of the specified classes\"\n",
        ")\n",
        "\n",
        "### BEGIN HIDDEN TESTS\n",
        "if isinstance(john_class, np.ndarray):\n",
        "    assert john_class.shape == (1,)\n",
        "    assert john_class[0] == 1\n",
        "else:\n",
        "    assert john_class == 1\n",
        "### END HIDDEN TESTS"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "713129e0",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "q9",
          "locked": false,
          "points": 2,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "## Q9 (2 pts) – Instance Prediction Continued\n",
        "\n",
        "Explain what the oputcome of your model's prediction for John means.\n",
        "### BEGIN SOLUTION\n",
        "1 means attrition, 0 means no attrition.\n",
        "### END SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "738031c8",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "q10_1",
          "locked": true,
          "points": 4,
          "schema_version": 3,
          "solution": false,
          "task": true
        }
      },
      "source": [
        "## Q10 (4 pts) – Visualize Decision Boundaries\n",
        "\n",
        "Pick two of the most influential features in your feature set (the ones you included in your final model), and plot decision boundaries for a range of K values. This range should include your chosen K value for your model as well.\n",
        "\n",
        "> **Notes:**\n",
        "> - Picking the most influential or determining feature can be somewhat subjective, and you may need to refer to what you did for your feature selection.\n",
        "> - You can copy the entire `plot_decision_boundary()` function definition from lecture notebook. And use it similar to how we used it in lecture notebook.\n",
        "> - Remember, the best K for the particular pair of features you choose here is not necessarily the best K for your fully fitted model. Why?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b6c89b1",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "q10_2",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "### BEGIN SOLUTION\n",
        "### END SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "557210ec",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "q11",
          "locked": false,
          "points": 5,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "## Q11 (5 pts) – Visualize Decision Boundaries Continued\n",
        "\n",
        "Explain which K value makes the most sense for this particular feature pair. Can you explain what the decision boundaries mean at this K level? How they explain classification of observations?\n",
        "\n",
        "### BEGIN SOLUTION\n",
        "### END SOLUTION"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "psych-723 (3.12.12)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "nbgrader": {
      "assignment_id": "hw2",
      "course_id": "psyc723",
      "notebook_id": "hw2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}